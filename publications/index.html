<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Eva Guttmann-Flury </title> <meta name="author" content="Eva Guttmann-Flury"> <meta name="description" content="Much Ado About Publications"> <meta name="keywords" content="Brain-Computer Interface (BCI), Electroencephalography (EEG), Artifact removal, Sample size calculation, Source Localization"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?53a094b51ed1d1e025731eb00d240058" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/brain_icon8.png?e26080812977a06ecb45772c34a320ce"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://qinxinlan.github.io/publications/"> <script src="/assets/js/theme.js?7b1068a1099d4262cace6933e385240d"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?46af317e693b09921dcb92261d123fbc" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Eva</span> Guttmann-Flury </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Projects </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/projects/">Overview</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/1_project/">Blinks</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/2_project/">Algorithms</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/3_project/">Variability</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/4_project/">Statistics</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="nav-item active"> <a class="nav-link" href="/zh/publications/"> ZH</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">Much Ado About Publications</p> </header> <article> <script src="/assets/js/bibsearch.js?8470e568bd8f7fe1a4046936bc17c40d" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Sci Data</abbr> </div> <div id="guttmannflury2024dataset" class="col-sm-8"> <div class="title">Dataset combining EEG, eye-tracking, and high-speed video for ocular activity analysis across BCI paradigms</div> <div class="author"> <em>E. Guttmann-Flury</em>, <a href="https://scholar.google.com/citations?user=A1ENH7gAAAAJ" rel="external nofollow noopener" target="_blank">X. Sheng</a>, and <a href="https://scholar.google.com/citations?hl=en&amp;user=MjW-8-cAAAAJ" rel="external nofollow noopener" target="_blank">X. Zhu</a> </div> <div class="periodical"> Apr 2024 </div> <div class="periodical"> Submitted to Scientific Data </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>In Brain-Computer Interface (BCI) research, the detailed study of blinks is crucial, as they significantly affect the efficiency and accuracy derived from various common paradigms, altering the decoding of users’ cognitive states and intentions. We introduce a large dataset that captures electroencephalogram (EEG) signals and incorporates eye-tracking, high-speed camera recordings, as well as subjects’ state of mind and characteristics, to provide a multifactor analysis of eye-related movements. Four distinct paradigms – motor imagery, motor execution, steady-state visually evoked potentials, and P300 spellers – are selected due to their capacity to evoke various sensory-motor responses and potential influence on ocular activity. The online-available dataset comprises over 46 hours of data collected from 31 subjects across 63 sessions, resulting in 2520 trials for each of the first three paradigms, and 5670 trials for P300. This multimodal and multi-paradigms dataset is expected to allow the development of algorithms capable of efficiently handling eye-induced artifacts and enhancing task-specific classification. Furthermore, it offers the opportunity to evaluate the cross-paradigm robustness involving the same participants.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@unpublished</span><span class="p">{</span><span class="nl">guttmannflury2024dataset</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dataset combining EEG, eye-tracking, and high-speed video for ocular activity analysis across BCI paradigms}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guttmann-Flury, E. and Sheng, X. and Zhu, X.}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Submitted to Scientific Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Brain-Computer Interfaces, Neuroscience, Cognitive science}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Sigradi 2024</abbr> </div> <div id="yang2024sigradi" class="col-sm-8"> <div class="title">EEG emotion recognition from AI-generated biodigital architecture images</div> <div class="author"> H. Yang, and <em>E. Guttmann-Flury</em> </div> <div class="periodical"> Jul 2024 </div> <div class="periodical"> Submitted to XXVIII Conference of the Ibero-American Society of Digital Graphics </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Emotional responses to biodigital architecture were examined using electroencephalographic (EEG) data from AI-generated images. A pre-experiment involving 336 participants identified 60 images, selected from an initial pool of 600, that elicited strong emotional responses categorized as awe, disgust, or content. These images were used for EEG recordings of 52 volunteers, with channel selection and sample size estimation based on the analysis of an existing dataset. Gamma and delta bands yielded the highest classification accuracy, with the gamma band achieving 77.07% ± 13.8% accuracy for the awe emotion. Key factors such as greenery and non-uniform granularity were linked to positive emotions, while dampness triggered negative reactions. These results emphasize the significance of incorporating natural elements and varied textures in biodigital architecture to enhance aesthetic appeal and acceptance. The study demonstrates EEG’s capability to objectively assess architectural preferences, providing valuable insights for architects to design engaging and sustainable environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@unpublished</span><span class="p">{</span><span class="nl">yang2024sigradi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{EEG emotion recognition from AI-generated biodigital architecture images}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang, H. and Guttmann-Flury, E.}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Submitted to XXVIII Conference of the Ibero-American Society of Digital Graphics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Biodigital architecture, Emotional classification, Electroencephalogram, EEG, Al-generated images, Deep learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Behav Res</abbr> </div> <div id="guttmannflury2022css" class="col-sm-8"> <div class="title">Channel selection from source localization: A review of four EEG-based brain–computer interfaces paradigms</div> <div class="author"> <em>E. Guttmann-Flury</em>, <a href="https://scholar.google.com/citations?user=A1ENH7gAAAAJ" rel="external nofollow noopener" target="_blank">X. Sheng</a>, and <a href="https://scholar.google.com/citations?hl=en&amp;user=MjW-8-cAAAAJ" rel="external nofollow noopener" target="_blank">X. Zhu</a> </div> <div class="periodical"> <em>Behavior Research Methods</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.researchgate.net/publication/361819223_Channel_selection_from_source_localization_A_review_of_four_EEG-based_brain-computer_interfaces_paradigms" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/guttmannflury2022css.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Channel selection is a critical part of the classification procedure for multichannel electroencephalogram (EEG)-based brain–computer interfaces (BCI). An optimized subset of electrodes reduces computational complexity and optimizes accuracy. Different tasks activate different sources in the brain and are characterized by distinctive channels. The goal of the current review is to define a subset of electrodes for each of four popular BCI paradigms: motor imagery, motor execution, steady-state visual evoked potentials and P300. Twenty-one studies have been reviewed to identify the most significant activations of cortical sources. The relevant EEG sensors are determined from the reported 3D Talairach coordinates. They are scored by their weighted mean Cohen’s d and its confidence interval, providing the magnitude of the corresponding effect size and its statistical significance. Our goal is to create a knowledge-based channel selection framework with a sufficient statistical power. The core channel selection (CCS) could be used as a reference by EEG researchers and would have the advantages of practicality and rapidity, allowing for an easy implementation of semiparametric algorithms.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">guttmannflury2022css</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Channel selection from source localization: A review of four EEG-based brain–computer interfaces paradigms}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guttmann-Flury, E. and Sheng, X. and Zhu, X.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Behavior Research Methods}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{55}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1980–2003}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3758/s13428-022-01897-2}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/article/10.3758/s13428-022-01897-2}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Channel selection, Electroencephalography, EEG, Brain computer interface, BCI, Motor imagery, Motor execution, SSVEP, P300}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Comput Biol Med</abbr> </div> <div id="guttmannflury2019abc" class="col-sm-8"> <div class="title">A new algorithm for blink correction adaptive to inter- and intra-subject variability</div> <div class="author"> <em>E. Guttmann-Flury</em>, <a href="https://scholar.google.com/citations?user=A1ENH7gAAAAJ" rel="external nofollow noopener" target="_blank">X. Sheng</a>, <a href="https://scholar.google.com/citations?user=59fHPRsAAAAJ" rel="external nofollow noopener" target="_blank">D. Zhang</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'X. Zhu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Computers in Biology and Medicine</em>, Jul 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.academia.edu/40785466/A_new_algorithm_for_blink_correction_adaptive_to_inter_and_intra_subject_variability" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/guttmannflury2019abc.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Electroencephalographic (EEG) signals are constantly superimposed with biological artifacts. In particular, spontaneous blinks represent a recurrent event that cannot be easily avoided. The main goal of this paper is to present a new algorithm for blink correction (ABC) that is adaptive to inter- and intra-subject variability. The whole process of designing a Brain-Computer Interface (BCI)-based EEG experiment is highlighted. From sample size determination to classification, a mixture of the standardized low-resolution electromagnetic tomography (sLORETA) for source localization and time restriction, followed by Riemannian geometry classifiers is featured. Comparison between ABC and the commonly-used Independent Component Analysis (ICA) for blinks removal shows a net amelioration with ABC. With the same pipeline using uncorrected data as a reference, ABC improves classification by 5.38% in average, whereas ICA deteriorates by −2.67%. Furthermore, while ABC accurately reconstructs blink-free data from simulated data, ICA yields a potential difference up to 200% from the original blink-free signal and an increased variance of 30.42%. Finally, ABC’s major advantages are ease of visualization and understanding, low computation load favoring simple real-time implementation, and lack of spatial filtering, which allows for more flexibility during the classification step.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">guttmannflury2019abc</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A new algorithm for blink correction adaptive to inter- and intra-subject variability}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guttmann-Flury, E. and Sheng, X. and Zhang, D. and Zhu, X.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers in Biology and Medicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{114}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{103442}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0010-4825}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.compbiomed.2019.103442}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/abs/pii/S0010482519303191}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Electroencephalography, EEG, Brain computer interface, BCI, Spontaneous blinking, Artifact removal, Sample size calculation, Standardized low-resolution electromagnetic tomography, sLORETA, Riemannian geometry, Independent component analysis, ICA}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMBC 2019</abbr> </div> <div id="guttmannflury2019apss" class="col-sm-8"> <div class="title">A Priori Sample Size Determination for the Number of Subjects in an EEG Experiment</div> <div class="author"> <em>E. Guttmann-Flury</em>, <a href="https://scholar.google.com/citations?user=A1ENH7gAAAAJ" rel="external nofollow noopener" target="_blank">X. Sheng</a>, <a href="https://scholar.google.com/citations?user=59fHPRsAAAAJ" rel="external nofollow noopener" target="_blank">D. Zhang</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'X. Zhu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>, Jul 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.researchgate.net/profile/Eva-Guttmann-Flury/publication/333045167_A_Priori_Sample_Size_Determination_for_the_Number_of_Subjects_in_an_EEG_Experiment/links/5cd947a592851c4eab9a40b3/A-Priori-Sample-Size-Determination-for-the-Number-of-Subjects-in-an-EEG-Experiment.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/guttmannflury2019apss.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This paper represents a first attempt to perform a priori sample size determination from a "historic" Electroencephalography (EEG) dataset. The importance of adequate sample size is firstly highlighted, and evidence is given against the use of normal distribution for such computations, when the data cannot be assumed to be Gaussian. The "historic" dataset is then thoroughly examined to determine the least less likely underlying distribution for the desired phenomenon, in this case the spontaneous blinks potential. Two Monte Carlo simulations, using different distribution assumptions, are subsequently computed to estimate the a priori minimum sample size. Finally, these choices are discussed considering practical limitations, as well as the computational differences for other phenomena to study.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">guttmannflury2019apss</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Priori Sample Size Determination for the Number of Subjects in an EEG Experiment}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guttmann-Flury, E. and Sheng, X. and Zhang, D. and Zhu, X.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5180-5183}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/EMBC.2019.8857482}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/8857482}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Electroencephalography, Gaussian distribution, Monte Carlo methods, Brain modeling, Computational modeling, Visualization}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NER 2019</abbr> </div> <div id="guttmannflury2019prabc" class="col-sm-8"> <div class="title">Preliminary Results on a New Algorithm for Blink Correction Adaptive to Inter- and Intra-Subject Variability</div> <div class="author"> <em>E. Guttmann-Flury</em>, <a href="https://scholar.google.com/citations?user=A1ENH7gAAAAJ" rel="external nofollow noopener" target="_blank">X. Sheng</a>, <a href="https://scholar.google.com/citations?user=59fHPRsAAAAJ" rel="external nofollow noopener" target="_blank">D. Zhang</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'X. Zhu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)</em>, Jul 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/1910.14292" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/guttmannflury2019prabc.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This paper presents a new preprocessing method to correct blinking artifacts in Electroencephalography (EEG) based Brain-Computer Interfaces (BCIs). This Algorithm for Blink Correction (ABC) directly corrects the signal in the time domain without the need for additional Electrooculogram (EOG) electrodes. The main idea is to automatically adapt to the blink’s inter- and intra-subject variability by considering the blink’s amplitude as a parameter. A simple Minimum Distance to Riemannian Mean (MDRM) is applied as the classification algorithm. Preliminary results on three subjects show a mean classification accuracy increase of 13.7% using ABC.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">guttmannflury2019prabc</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Preliminary Results on a New Algorithm for Blink Correction Adaptive to Inter- and Intra-Subject Variability}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guttmann-Flury, E. and Sheng, X. and Zhang, D. and Zhu, X.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{585-588}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/NER.2019.8717029}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/8717029}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Electroencephalography, Covariance matrices, Electrodes, Electrooculography, Classification algorithms}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Eva Guttmann-Flury. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/george-gca/multi-language-al-folio" rel="external nofollow noopener" target="_blank">multi-language-al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?b977fe0c21b2118ed853308b1b923969"></script> <script src="/assets/js/no_defer.js?699fa7cbe3b29f831db7d5250ba3203a"></script> <script defer src="/assets/js/common.js?d3a25b46bbd2e0a751a27b173abc6e5f"></script> <script defer src="/assets/js/copy_code.js?d359581efc54b08366f9ef8219e6e511" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?25eff8ff4144a010e4ad7b31403102cf"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.getElementById("WeChatBtn");wechatBtn.onclick=function(){wechatModal.style.display="block"},window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?66cb7c6fd8c87d040727f1e99683717e"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"> <div class="modal-footer" slot="footer"> <span class="help"> <svg version="1.0" class="ninja-examplekey" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 1280 1280"> <path d="M1013 376c0 73.4-.4 113.3-1.1 120.2a159.9 159.9 0 0 1-90.2 127.3c-20 9.6-36.7 14-59.2 15.5-7.1.5-121.9.9-255 1h-242l95.5-95.5 95.5-95.5-38.3-38.2-38.2-38.3-160 160c-88 88-160 160.4-160 161 0 .6 72 73 160 161l160 160 38.2-38.3 38.3-38.2-95.5-95.5-95.5-95.5h251.1c252.9 0 259.8-.1 281.4-3.6 72.1-11.8 136.9-54.1 178.5-116.4 8.6-12.9 22.6-40.5 28-55.4 4.4-12 10.7-36.1 13.1-50.6 1.6-9.6 1.8-21 2.1-132.8l.4-122.2H1013v110z"></path> </svg> to select </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M20 12l-1.41-1.41L13 16.17V4h-2v12.17l-5.58-5.59L4 12l8 8 8-8z"></path> </svg> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M4 12l1.41 1.41L11 7.83V20h2V7.83l5.58 5.59L20 12l-8-8-8 8z"></path> </svg> to navigate </span> <span class="help"> <span class="ninja-examplekey esc">esc</span> to close </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey backspace" viewbox="0 0 20 20" fill="currentColor"> <path fill-rule="evenodd" d="M6.707 4.879A3 3 0 018.828 4H15a3 3 0 013 3v6a3 3 0 01-3 3H8.828a3 3 0 01-2.12-.879l-4.415-4.414a1 1 0 010-1.414l4.414-4.414zm4 2.414a1 1 0 00-1.414 1.414L10.586 10l-1.293 1.293a1 1 0 101.414 1.414L12 11.414l1.293 1.293a1 1 0 001.414-1.414L13.414 10l1.293-1.293a1 1 0 00-1.414-1.414L12 8.586l-1.293-1.293z" clip-rule="evenodd"></path> </svg> move to parent </span> </div> </ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation menu",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"Publications",description:"Much Ado About Publications",section:"Navigation menu",handler:()=>{window.location.href="/publications/"}},{id:"dropdown-overview",title:"Overview",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blinks",title:"Blinks",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-algorithms",title:"Algorithms",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-variability",title:"Variability",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-statistics",title:"Statistics",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"nav-cv",title:"CV",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation menu",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/en-us/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2018/distill/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-blinks",title:"Blinks",description:"A pulsar for EEG signals",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-algorithms",title:"Algorithms",description:"An endless labyrinth of possibilities",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-variability",title:"Variability",description:"A certainty as elusive as a fleeting shadow",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-statistics",title:"Statistics",description:"An unerring compass guiding towards the truth",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"socials-email",title:"Send an email",section:"Socials",handler:()=>{window.open("mailto:%65%76%61.%67%75%74%74%6D%61%6E%6E.%66%6C%75%72%79@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=pamaGFEAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/QinXinlan","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/eva-guttmann-flury","_blank")}},{id:"socials-kaggle",title:"Kaggle",section:"Socials",handler:()=>{window.open("https://www.kaggle.com/qinxinlaneva","_blank")}},{id:"lang-zh",title:"zh",section:"Languages",handler:()=>{window.location.href="/zh/publications/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?f74bfa9a88ab862fb9df1c46146b7b7d"></script> </body> </html>